import os
import json
import logging
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Optional, Tuple
import re
from django.conf import settings
from django.db.models import Count, Q, Max, Min, Avg, F, Case, When, Value, CharField
from django.utils import timezone
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side, NamedStyle
from openpyxl.utils import get_column_letter
from openpyxl.chart import BarChart, PieChart, LineChart, Reference
from openpyxl.drawing.image import Image
from monitor.models import Documento, NormaVigente, TermoMonitorado, RelatorioGerado


# Importa√ß√µes para IA gratuita
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
    import torch
    IA_DISPONIVEL = True
except ImportError:
    IA_DISPONIVEL = False
    print("‚ö†Ô∏è Bibliotecas de IA n√£o instaladas. Para usar IA gratuita, instale: pip install transformers torch")

from monitor.models import Documento, NormaVigente

logger = logging.getLogger(__name__)

class IAGratuita:
    """Classe para integra√ß√£o com modelos de IA gratuitos"""
    
    def __init__(self):
        self.resumidor = None
        self.analisador_sentimento = None
        self.extrator_keywords = None
        self._inicializar_modelos()
    
    def _inicializar_modelos(self):
        """Inicializa os modelos de IA gratuitos"""
        if not IA_DISPONIVEL:
            logger.warning("Bibliotecas de IA n√£o dispon√≠veis. Funcionalidades limitadas.")
            return
        
        try:
            # Modelo para resumos em portugu√™s (leve e eficiente)
            self.resumidor = pipeline(
                "summarization",
                model="facebook/bart-large-cnn",  # Modelo em ingl√™s, mas funciona bem
                tokenizer="facebook/bart-large-cnn",
                device=-1  # CPU (use 0 para GPU se dispon√≠vel)
            )
            
            # Alternativa em portugu√™s (se dispon√≠vel)
            # self.resumidor = pipeline("summarization", model="pierreguillou/gpt2-small-portuguese")
            
            # Analisador de sentimento
            self.analisador_sentimento = pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                device=-1
            )
            
            logger.info("‚úÖ Modelos de IA inicializados com sucesso")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar modelos de IA: {e}")
            self.resumidor = None
            self.analisador_sentimento = None
    
    def gerar_resumo_inteligente(self, texto, max_length=150):
        """Gera resumo inteligente usando IA gratuita"""
        if not self.resumidor or not texto:
            return self._resumo_fallback(texto, max_length)
        
        try:
            # Limpa e prepara o texto
            texto_limpo = self._limpar_texto_para_ia(texto)
            
            # Se o texto for muito curto, retorna como est√°
            if len(texto_limpo.split()) < 20:
                return texto_limpo
            
            # Gera resumo com IA
            resultado = self.resumidor(
                texto_limpo,
                max_length=max_length,
                min_length=30,
                do_sample=False,
                truncation=True
            )
            
            resumo = resultado[0]['summary_text']
            
            # P√≥s-processamento
            resumo = self._pos_processar_resumo(resumo)
            
            logger.debug(f"‚úÖ Resumo IA gerado: {len(resumo)} chars")
            return resumo
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de resumo IA: {e}")
            return self._resumo_fallback(texto, max_length)
    
    def extrair_palavras_chave_ia(self, texto, num_palavras=10):
        """Extrai palavras-chave usando t√©cnicas de IA"""
        if not texto:
            return []
        
        try:
            # M√©todo 1: TF-IDF simples (sempre dispon√≠vel)
            palavras_chave = self._extrair_tfidf(texto, num_palavras)
            
            # M√©todo 2: Se IA dispon√≠vel, refinamento com an√°lise sem√¢ntica
            if self.resumidor:
                palavras_chave = self._refinar_palavras_chave_ia(texto, palavras_chave)
            
            return palavras_chave[:num_palavras]
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o de palavras-chave: {e}")
            return self._extrair_palavras_chave_basico(texto)
    
    def analisar_sentimento_documento(self, texto):
        """Analisa o sentimento/tom do documento"""
        if not self.analisador_sentimento or not texto:
            return {"sentimento": "neutro", "confianca": 0.5}
        
        try:
            # Pega uma amostra do texto (modelos t√™m limite de tokens)
            amostra = texto[:500]
            
            resultado = self.analisador_sentimento(amostra)
            
            # Mapeia labels para portugu√™s
            mapeamento = {
                'POSITIVE': 'positivo',
                'NEGATIVE': 'negativo', 
                'NEUTRAL': 'neutro',
                'LABEL_0': 'negativo',
                'LABEL_1': 'neutro',
                'LABEL_2': 'positivo'
            }
            
            sentimento = mapeamento.get(resultado[0]['label'], 'neutro')
            confianca = resultado[0]['score']
            
            return {
                "sentimento": sentimento,
                "confianca": confianca,
                "interpretacao": self._interpretar_sentimento_contabil(sentimento, confianca)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de sentimento: {e}")
            return {"sentimento": "neutro", "confianca": 0.5, "interpretacao": "An√°lise n√£o dispon√≠vel"}
    
    def gerar_insights_automaticos(self, documentos, normas):
        """Gera insights autom√°ticos usando IA"""
        insights = []
        
        try:
            # Insight 1: An√°lise temporal de assuntos
            insights.append(self._analisar_tendencia_assuntos(documentos))
            
            # Insight 2: Padr√µes em normas
            insights.append(self._analisar_padroes_normas(normas))
            
            # Insight 3: An√°lise de compliance
            insights.append(self._analisar_compliance_inteligente(normas))
            
            # Insight 4: Recomenda√ß√µes contextuais
            insights.extend(self._gerar_recomendacoes_contextuais(documentos, normas))
            
            return [i for i in insights if i]  # Remove insights vazios
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de insights: {e}")
            return []
    
    # M√©todos auxiliares
    def _limpar_texto_para_ia(self, texto):
        """Limpa e prepara texto para processamento de IA"""
        if not texto:
            return ""
        
        # Remove caracteres especiais excessivos
        texto = re.sub(r'[^\w\s\.\,\;\:\!\?\-]', ' ', texto)
        
        # Remove espa√ßos m√∫ltiplos
        texto = re.sub(r'\s+', ' ', texto)
        
        # Limita tamanho (modelos t√™m limite de tokens)
        palavras = texto.split()
        if len(palavras) > 500:  # ~400 tokens aprox
            texto = ' '.join(palavras[:500])
        
        return texto.strip()
    
    def _pos_processar_resumo(self, resumo):
        """P√≥s-processa o resumo gerado pela IA"""
        if not resumo:
            return ""
        
        # Capitaliza primeira letra
        resumo = resumo[0].upper() + resumo[1:] if len(resumo) > 1 else resumo.upper()
        
        # Remove frases incompletas no final
        if not resumo.endswith('.'):
            ultima_frase = resumo.rfind('.')
            if ultima_frase > len(resumo) * 0.7:  # Se h√° uma frase quase completa
                resumo = resumo[:ultima_frase + 1]
            else:
                resumo += "."
        
        return resumo
    
    def _resumo_fallback(self, texto, max_length):
        """Sistema de resumo alternativo quando IA n√£o dispon√≠vel"""
        if not texto:
            return "Texto n√£o dispon√≠vel para resumo."
        
        # Pega as primeiras frases at√© atingir o limite
        frases = re.split(r'[.!?]+', texto)
        resumo = ""
        
        for frase in frases:
            frase_limpa = frase.strip()
            if len(resumo + frase_limpa) < max_length:
                resumo += frase_limpa + ". "
            else:
                break
        
        return resumo.strip() or texto[:max_length] + "..."
    
    def _extrair_tfidf(self, texto, num_palavras):
        """Extra√ß√£o de palavras-chave usando TF-IDF simplificado"""
        from collections import Counter
        import math
        
        # Remove stop words
        stop_words = {
            'de', 'da', 'do', 'das', 'dos', 'em', 'na', 'no', 'nas', 'nos',
            'para', 'por', 'com', 'sem', 'sobre', 'entre', 'at√©', 'desde',
            'que', 'como', 'quando', 'onde', 'porque', 'se', 'mas', 'ou',
            'e', 'a', 'o', 'as', 'os', 'um', 'uma', 'uns', 'umas', '√©', 's√£o',
            'foi', 'foram', 'ser√°', 'ser√£o', 'tem', 't√™m', 'teve', 'tiveram'
        }
        
        # Extrai palavras
        palavras = re.findall(r'\b\w{3,}\b', texto.lower())
        palavras_filtradas = [p for p in palavras if p not in stop_words and len(p) > 3]
        
        # Calcula frequ√™ncia
        freq = Counter(palavras_filtradas)
        
        # Ordena por relev√¢ncia (frequ√™ncia e tamanho)
        palavras_relevantes = sorted(
            freq.items(), 
            key=lambda x: x[1] * len(x[0]) * 0.1, 
            reverse=True
        )
        
        return [palavra for palavra, _ in palavras_relevantes[:num_palavras]]
    
    def _refinar_palavras_chave_ia(self, texto, palavras_iniciais):
        """Refina palavras-chave usando contexto de IA"""
        # Aqui voc√™ pode implementar refinamento mais sofisticado
        # Por ora, retorna as palavras iniciais com algum filtro
        
        # Filtra palavras muito comuns em documentos legais
        filtros_contextuais = {'artigo', 'inciso', 'paragrafo', 'lei', 'decreto', 'portaria'}
        palavras_refinadas = [p for p in palavras_iniciais if p not in filtros_contextuais]
        
        return palavras_refinadas
    
    def _extrair_palavras_chave_basico(self, texto):
        """M√©todo b√°sico para extra√ß√£o quando IA n√£o dispon√≠vel"""
        return self._extrair_tfidf(texto, 5)
    
    def _interpretar_sentimento_contabil(self, sentimento, confianca):
        """Interpreta sentimento no contexto cont√°bil"""
        if confianca < 0.6:
            return "Neutro - baixa confian√ßa na an√°lise"
        
        interpretacoes = {
            'positivo': "Documento com tom regulamentador/orientativo",
            'negativo': "Documento com tom restritivo/punitivo", 
            'neutro': "Documento com tom informativo/t√©cnico"
        }
        
        return interpretacoes.get(sentimento, "Tom n√£o identificado")
    
    def _analisar_tendencia_assuntos(self, documentos):
        """Analisa tend√™ncias nos assuntos usando IA"""
        if not documentos:
            return None
        
        # Agrupa assuntos por per√≠odo
        assuntos_recentes = []
        data_limite = datetime.now() - timedelta(days=90)
        
        for doc in documentos:
            if doc.data_publicacao >= data_limite and doc.assunto:
                assuntos_recentes.append(doc.assunto)
        
        if not assuntos_recentes:
            return None
        
        # Extrai temas emergentes
        texto_combinado = ". ".join(assuntos_recentes)
        palavras_chave = self.extrair_palavras_chave_ia(texto_combinado, 5)
        
        return {
            "tipo": "TEND√äNCIA",
            "titulo": "Temas Emergentes Identificados",
            "descricao": f"An√°lise dos √∫ltimos 90 dias identificou tend√™ncias em: {', '.join(palavras_chave[:3])}",
            "relevancia": "alta" if len(palavras_chave) >= 3 else "m√©dia"
        }
    
    def _analisar_padroes_normas(self, normas):
        """Analisa padr√µes nas normas usando IA"""
        if not normas:
            return None
        
        # Analisa distribui√ß√£o de tipos
        tipos_freq = Counter([n.tipo for n in normas if n.tipo])
        tipo_dominante = tipos_freq.most_common(1)[0] if tipos_freq else None
        
        if not tipo_dominante:
            return None
        
        return {
            "tipo": "PADR√ÉO",
            "titulo": f"Predomin√¢ncia de {tipo_dominante[0]}",
            "descricao": f"Identificadas {tipo_dominante[1]} normas do tipo {tipo_dominante[0]}, representando {tipo_dominante[1]/len(normas)*100:.1f}% do total",
            "relevancia": "alta" if tipo_dominante[1] > len(normas) * 0.4 else "m√©dia"
        }
    
    def _analisar_compliance_inteligente(self, normas):
        """An√°lise inteligente de compliance"""
        if not normas:
            return None
        
        problematicas = len([n for n in normas if n.situacao in ['REVOGADA', 'N√ÉO ENCONTRADA']])
        total = len(normas)
        percentual_problema = (problematicas / total * 100) if total > 0 else 0
        
        if percentual_problema > 15:
            return {
                "tipo": "RISCO",
                "titulo": "Alto Risco de Compliance Detectado",
                "descricao": f"{percentual_problema:.1f}% das normas apresentam problemas de vig√™ncia",
                "relevancia": "cr√≠tica"
            }
        
        return None
    
    def _gerar_recomendacoes_contextuais(self, documentos, normas):
        """Gera recomenda√ß√µes baseadas no contexto atual"""
        recomendacoes = []
        
        # Recomenda√ß√£o baseada em processamento
        nao_processados = len([d for d in documentos if not d.processado])
        if nao_processados > len(documentos) * 0.2:  # Mais de 20% n√£o processados
            recomendacoes.append({
                "tipo": "PROCESSAMENTO",
                "titulo": "Acelerar Processamento de Documentos",
                "descricao": f"{nao_processados} documentos aguardam processamento completo",
                "relevancia": "alta"
            })
        
        # Recomenda√ß√£o baseada em verifica√ß√£o de normas
        nao_verificadas = len([n for n in normas if not n.data_verificacao])
        if nao_verificadas > 0:
            recomendacoes.append({
                "tipo": "VERIFICA√á√ÉO",
                "titulo": "Implementar Verifica√ß√£o Sistem√°tica",
                "descricao": f"{nao_verificadas} normas precisam de verifica√ß√£o de status",
                "relevancia": "m√©dia"
            })
        
        return recomendacoes


class AnaliseIA:
    """Classe respons√°vel por an√°lises avan√ßadas com IA dos documentos e normas"""
    
    def __init__(self):
        self.ia_gratuita = IAGratuita()
    
    @staticmethod
    def analisar_tendencias_normativas(documentos):
        """Analisa tend√™ncias nas normas mencionadas nos documentos"""
        tendencias = {
            'normas_mais_citadas': [],
            'tipos_normas_frequentes': {},
            'evolucao_temporal': {},
            'assuntos_emergentes': [],
            'correlacoes_normas': {}
        }
        
        # An√°lise de frequ√™ncia de normas
        normas_freq = defaultdict(int)
        tipos_freq = defaultdict(int)
        assuntos_por_mes = defaultdict(list)
        
        for doc in documentos:
            mes_ano = doc.data_publicacao.strftime('%Y-%m')
            assuntos_por_mes[mes_ano].append(doc.assunto or '')
            
            for norma in doc.normas_relacionadas.all():
                norma_key = f"{norma.tipo} {norma.numero}"
                normas_freq[norma_key] += 1
                tipos_freq[norma.tipo] += 1
        
        # Top normas mais citadas
        tendencias['normas_mais_citadas'] = sorted(
            normas_freq.items(), key=lambda x: x[1], reverse=True
        )[:10]
        
        # Tipos mais frequentes
        tendencias['tipos_normas_frequentes'] = dict(tipos_freq)
        
        # Evolu√ß√£o temporal
        tendencias['evolucao_temporal'] = dict(assuntos_por_mes)
        
        # Identificar assuntos emergentes usando an√°lise de keywords
        assuntos_emergentes = AnaliseIA._identificar_assuntos_emergentes(assuntos_por_mes)
        tendencias['assuntos_emergentes'] = assuntos_emergentes
        
        return tendencias
    
    @staticmethod
    def _identificar_assuntos_emergentes(assuntos_por_mes):
        """Identifica assuntos que est√£o crescendo em frequ√™ncia"""
        palavras_chave = defaultdict(lambda: defaultdict(int))
        
        # An√°lise de palavras-chave por m√™s
        for mes, assuntos in assuntos_por_mes.items():
            for assunto in assuntos:
                if assunto:
                    palavras = re.findall(r'\b\w{4,}\b', assunto.lower())
                    for palavra in palavras:
                        palavras_chave[palavra][mes] += 1
        
        # Identificar tend√™ncias crescentes
        emergentes = []
        meses_ordenados = sorted(assuntos_por_mes.keys())
        
        for palavra, freq_mensal in palavras_chave.items():
            if len(freq_mensal) >= 3:  # Pelo menos 3 meses de dados
                frequencias = [freq_mensal.get(mes, 0) for mes in meses_ordenados[-6:]]
                if len(frequencias) >= 3:
                    # Calcular tend√™ncia (crescimento)
                    crescimento = sum(frequencias[-3:]) - sum(frequencias[:3])
                    if crescimento > 0:
                        emergentes.append((palavra, crescimento))
        
        return sorted(emergentes, key=lambda x: x[1], reverse=True)[:10]
    
    def gerar_resumo_executivo(self, documentos, normas):
        """Gera resumo executivo inteligente dos dados com IA"""
        total_docs = len(documentos)
        total_normas = len(normas)
        
        # An√°lise temporal
        if documentos:
            doc_mais_recente = max(documentos, key=lambda d: d.data_publicacao)
            doc_mais_antigo = min(documentos, key=lambda d: d.data_publicacao)
            periodo = (doc_mais_recente.data_publicacao - doc_mais_antigo.data_publicacao).days
        else:
            periodo = 0
        
        # An√°lise de relev√¢ncia cont√°bil
        docs_contabeis = [d for d in documentos if d.relevante_contabil]
        taxa_relevancia = (len(docs_contabeis) / total_docs * 100) if total_docs > 0 else 0
        
        # An√°lise de normas
        normas_vigentes = [n for n in normas if n.situacao == 'VIGENTE']
        normas_revogadas = [n for n in normas if n.situacao == 'REVOGADA']
        normas_nao_encontradas = [n for n in normas if n.situacao == 'N√ÉO ENCONTRADA']
        
        # An√°lise de fontes
        fontes_confirmacao = Counter([n.fonte_confirmacao for n in normas if n.fonte_confirmacao])
        
        # üÜï An√°lises com IA Gratuita
        insights_ia = self.ia_gratuita.gerar_insights_automaticos(documentos, normas)
        
        # üÜï An√°lise de sentimento dos documentos
        sentimentos = []
        for doc in documentos[:10]:  # Analisa uma amostra
            if doc.resumo or doc.titulo:
                sentimento = self.ia_gratuita.analisar_sentimento_documento(doc.resumo or doc.titulo)
                sentimentos.append(sentimento)
        
        # üÜï Resumo inteligente dos principais assuntos
        principais_assuntos = [doc.assunto for doc in documentos if doc.assunto][:5]
        resumo_assuntos = ""
        if principais_assuntos:
            texto_assuntos = ". ".join(principais_assuntos)
            resumo_assuntos = self.ia_gratuita.gerar_resumo_inteligente(texto_assuntos, 100)
        
        resumo = {
            'periodo_analise': f"{periodo} dias" if periodo > 0 else "N/A",
            'total_documentos': total_docs,
            'documentos_contabeis': len(docs_contabeis),
            'taxa_relevancia_contabil': f"{taxa_relevancia:.1f}%",
            'total_normas': total_normas,
            'normas_vigentes': len(normas_vigentes),
            'normas_revogadas': len(normas_revogadas),
            'normas_problematicas': len(normas_nao_encontradas),
            'fontes_principais': dict(fontes_confirmacao.most_common(3)),
            'risco_compliance': self._calcular_risco_compliance(normas),
            'recomendacoes': self._gerar_recomendacoes(documentos, normas),
            
            # üÜï Campos com IA
            'insights_ia': insights_ia,
            'analise_sentimento': self._processar_sentimentos(sentimentos),
            'resumo_assuntos_ia': resumo_assuntos,
            'palavras_chave_periodo': self.ia_gratuita.extrair_palavras_chave_ia(resumo_assuntos, 8) if resumo_assuntos else []
        }
        
        return resumo
    
    def _processar_sentimentos(self, sentimentos):
        """Processa an√°lise de sentimentos dos documentos"""
        if not sentimentos:
            return {"predominante": "neutro", "distribuicao": {}, "interpretacao": "An√°lise n√£o dispon√≠vel"}
        
        # Conta distribui√ß√£o
        distribuicao = Counter([s['sentimento'] for s in sentimentos])
        predominante = distribuicao.most_common(1)[0][0] if distribuicao else "neutro"
        
        # Calcula confian√ßa m√©dia
        confianca_media = sum([s['confianca'] for s in sentimentos]) / len(sentimentos)
        
        return {
            "predominante": predominante,
            "distribuicao": dict(distribuicao),
            "confianca_media": f"{confianca_media:.2f}",
            "interpretacao": f"Tom predominante: {predominante} (confian√ßa: {confianca_media:.1%})"
        }
    
    @staticmethod
    def _calcular_risco_compliance(normas):
        """Calcula score de risco de compliance baseado no status das normas"""
        if not normas:
            return "BAIXO"
        
        total = len(normas)
        problematicas = len([n for n in normas if n.situacao in ['N√ÉO ENCONTRADA', 'REVOGADA']])
        nao_verificadas = len([n for n in normas if not n.data_verificacao])
        
        score_problema = (problematicas / total) * 100
        score_verificacao = (nao_verificadas / total) * 100
        
        risco_total = score_problema + (score_verificacao * 0.5)
        
        if risco_total > 30:
            return "ALTO"
        elif risco_total > 15:
            return "M√âDIO"
        else:
            return "BAIXO"
    
    @staticmethod
    def _gerar_recomendacoes(documentos, normas):
        """Gera recomenda√ß√µes baseadas na an√°lise dos dados"""
        recomendacoes = []
        
        # An√°lise de normas problem√°ticas
        normas_problema = [n for n in normas if n.situacao in ['N√ÉO ENCONTRADA', 'REVOGADA']]
        if normas_problema:
            recomendacoes.append({
                'tipo': 'CR√çTICO',
                'titulo': 'Normas Problem√°ticas Identificadas',
                'descricao': f"Encontradas {len(normas_problema)} normas com status problem√°tico que requerem aten√ß√£o imediata",
                'acao': 'Revisar e atualizar refer√™ncias normativas'
            })
        
        # An√°lise de verifica√ß√£o
        nao_verificadas = [n for n in normas if not n.data_verificacao]
        if nao_verificadas:
            recomendacoes.append({
                'tipo': 'IMPORTANTE',
                'titulo': 'Normas N√£o Verificadas',
                'descricao': f"{len(nao_verificadas)} normas ainda n√£o foram verificadas",
                'acao': 'Implementar processo de verifica√ß√£o sistem√°tica'
            })
        
        # An√°lise de documentos n√£o processados
        nao_processados = [d for d in documentos if not d.processado]
        if nao_processados:
            recomendacoes.append({
                'tipo': 'MELHORIA',
                'titulo': 'Documentos Pendentes',
                'descricao': f"{len(nao_processados)} documentos aguardam processamento",
                'acao': 'Acelerar processamento de documentos pendentes'
            })
        
        return recomendacoes


# Resto do c√≥digo permanece igual...
class RelatorioAvancado:
    """Gerador de relat√≥rios avan√ßados com an√°lises de IA e visualiza√ß√µes"""
    
    def __init__(self):
        self.wb = None
        self.estilos = self._criar_estilos()
        self.ia_gratuita = IAGratuita()  # üÜï Adiciona IA gratuita
    
    def _criar_estilos(self):
        """Cria estilos padronizados para as planilhas"""
        estilos = {}
        
        # Estilo do t√≠tulo principal
        estilos['titulo_principal'] = {
            'font': Font(size=16, bold=True, color="1F4E78"),
            'alignment': Alignment(horizontal='center', vertical='center'),
            'fill': PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
        }
        
        # Estilo do cabe√ßalho
        estilos['cabecalho'] = {
            'font': Font(color="FFFFFF", bold=True, size=11),
            'fill': PatternFill(start_color="1F4E78", end_color="1F4E78", fill_type="solid"),
            'border': Border(
                bottom=Side(border_style="medium", color="FFFFFF"),
                top=Side(border_style="thin", color="FFFFFF"),
                left=Side(border_style="thin", color="FFFFFF"),
                right=Side(border_style="thin", color="FFFFFF")
            ),
            'alignment': Alignment(horizontal='center', vertical='center', wrap_text=True)
        }
        
        # Estilo zebrado
        estilos['zebra'] = PatternFill(start_color="F8F9FA", end_color="F8F9FA", fill_type="solid")
        
        # Estilo de alerta
        estilos['alerta'] = PatternFill(start_color="FFE6E6", end_color="FFE6E6", fill_type="solid")
        
        # Estilo de sucesso
        estilos['sucesso'] = PatternFill(start_color="E6F3E6", end_color="E6F3E6", fill_type="solid")
        
        # Estilo de aviso
        estilos['aviso'] = PatternFill(start_color="FFF3CD", end_color="FFF3CD", fill_type="solid")
        
        return estilos
    
    
    def gerar_relatorio_completo(self):
        """Gera relat√≥rio completo com todas as an√°lises e dados"""
        try:
            logger.info("üöÄ Iniciando gera√ß√£o de relat√≥rio completo...")
            
            # Busca dados
            documentos = list(Documento.objects.all().order_by('-data_publicacao'))
            normas = list(NormaVigente.objects.all().order_by('tipo', 'numero'))
            
            # Cria workbook
            self.wb = Workbook()
            
            # Remove planilha padr√£o
            if 'Sheet' in self.wb.sheetnames:
                self.wb.remove(self.wb['Sheet'])
            
            # Gera planilhas
            ws_resumo = self._criar_resumo_executivo(documentos, normas)
            ws_ia = self._criar_analise_ia(documentos, normas)
            self._criar_resumo_executivo(documentos, normas)
            self._criar_analise_documentos(documentos)
            self._criar_analise_normas(normas)
            self._criar_analise_compliance(normas)
            self._criar_tendencias_temporais(documentos)
            self._criar_analise_ia(documentos, normas)  # üÜï Nova aba com IA
            self._criar_dashboard_visual(documentos, normas)
            self._adicionar_analise_contextual(documentos, normas, ws_resumo)
            self._adicionar_impacto_regulatorio(normas, ws_resumo)
            #self._adicionar_resumos_especificos(documentos, ws_ia)
            #self._adicionar_termos_contabeis(documentos, ws_ia)
            
            # Salva arquivo
            nome_arquivo = f"relatorio_compliance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            caminho_arquivo = os.path.join(settings.MEDIA_ROOT, 'relatorios', nome_arquivo)
            
            # Cria diret√≥rio se n√£o existir
            os.makedirs(os.path.dirname(caminho_arquivo), exist_ok=True)
            
            self.wb.save(caminho_arquivo)
            
            logger.info(f"‚úÖ Relat√≥rio completo gerado: {nome_arquivo}")
            return caminho_arquivo
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o do relat√≥rio completo: {e}")
            raise


    def _adicionar_analise_contextual(self, documentos, normas, worksheet):
        """Adiciona an√°lise contextual ao resumo executivo"""
        row = worksheet.max_row + 2
        
        # An√°lise contextual dos documentos
        worksheet[f'A{row}'] = "AN√ÅLISE CONTEXTUAL"
        self._aplicar_estilo(worksheet[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        # Resumo IA dos documentos mais relevantes
        docs_relevantes = [d for d in documentos if d.relevante_contabil][:5]
        texto_analise = ". ".join(d.resumo or d.titulo for d in docs_relevantes)
        resumo_contexto = self.ia_gratuita.gerar_resumo_inteligente(texto_analise, 150)
        
        worksheet[f'A{row}'] = "Contexto Regulat√≥rio"
        worksheet[f'B{row}'] = resumo_contexto
        worksheet[f'B{row}'].alignment = Alignment(wrap_text=True)
        row += 1
        
        # Mudan√ßas desde o √∫ltimo relat√≥rio
        ultimo_relatorio = RelatorioGerado.objects.order_by('-data_criacao').first()
        if ultimo_relatorio:
            worksheet[f'A{row}'] = "Principais Mudan√ßas"
            mudancas = self._analisar_mudancas(documentos, normas, ultimo_relatorio)
            worksheet[f'B{row}'] = mudances
            worksheet[f'B{row}'].alignment = Alignment(wrap_text=True)



    def _adicionar_impacto_regulatorio(self, normas, worksheet):
        """Adiciona an√°lise de impacto regulat√≥rio"""
        normas_vigentes = [n for n in normas if n.situacao == 'VIGENTE']
        normas_novas = [n for n in normas_vigentes 
                       if n.data_verificacao and (timezone.now() - n.data_verificacao).days < 30]
        
        if normas_novas:
            row = worksheet.max_row + 2
            worksheet[f'A{row}'] = "IMPACTO REGULAT√ìRIO"
            self._aplicar_estilo(worksheet[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            worksheet[f'A{row}'] = "Novas Normas Vigentes"
            worksheet[f'B{row}'] = f"{len(normas_novas)} normas vigentes identificadas nos √∫ltimos 30 dias"
            
            # An√°lise de impacto das novas normas
            texto_normas = ". ".join(f"{n.tipo} {n.numero}: {n.ementa}" for n in normas_novas)
            impacto = self.ia_gratuita.gerar_resumo_inteligente(
                f"An√°lise de impacto cont√°bil das seguintes normas: {texto_normas}", 
                200
            )
            row += 1
            worksheet[f'A{row}'] = "An√°lise de Impacto"
            worksheet[f'B{row}'] = impacto
            worksheet[f'B{row}'].alignment = Alignment(wrap_text=True)



    
    
    def _criar_resumo_executivo(self, documentos, normas):
        """Cria aba com resumo executivo"""
        ws = self.wb.create_sheet(title="üìä Resumo Executivo")
        
        # Gera an√°lise IA
        analise_ia = AnaliseIA()
        resumo = analise_ia.gerar_resumo_executivo(documentos, normas)
        
        row = 1
        
        # T√≠tulo principal
        ws.merge_cells(f'A{row}:H{row}')
        ws[f'A{row}'] = "RELAT√ìRIO EXECUTIVO DE COMPLIANCE CONT√ÅBIL"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['titulo_principal'])
        row += 2
        
        # Informa√ß√µes gerais
        ws[f'A{row}'] = "INFORMA√á√ïES GERAIS"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        infos_gerais = [
            ("Per√≠odo de An√°lise", resumo['periodo_analise']),
            ("Total de Documentos", resumo['total_documentos']),
            ("Documentos Cont√°beis", resumo['documentos_contabeis']),
            ("Taxa de Relev√¢ncia Cont√°bil", resumo['taxa_relevancia_contabil']),
            ("Total de Normas", resumo['total_normas']),
            ("Normas Vigentes", resumo['normas_vigentes']),
            ("Normas Revogadas", resumo['normas_revogadas']),
            ("Normas Problem√°ticas", resumo['normas_problematicas']),
            ("Risco de Compliance", resumo['risco_compliance'])
        ]
        
        for info, valor in infos_gerais:
            ws[f'A{row}'] = info
            ws[f'B{row}'] = valor
            
            # Colora√ß√£o baseada no tipo de informa√ß√£o
            if "Risco" in info:
                if valor == "ALTO":
                    ws[f'B{row}'].fill = self.estilos['alerta']
                elif valor == "M√âDIO":
                    ws[f'B{row}'].fill = self.estilos['aviso']
                else:
                    ws[f'B{row}'].fill = self.estilos['sucesso']
            
            row += 1
        
        row += 2
        
        # üÜï Se√ß√£o de An√°lise com IA
        if resumo.get('insights_ia'):
            ws[f'A{row}'] = "INSIGHTS GERADOS POR IA"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            for insight in resumo['insights_ia']:
                ws[f'A{row}'] = f"üîç {insight['titulo']}"
                ws[f'B{row}'] = insight['descricao']
                
                # Cor baseada na relev√¢ncia
                if insight.get('relevancia') == 'cr√≠tica':
                    ws[f'A{row}'].fill = self.estilos['alerta']
                elif insight.get('relevancia') == 'alta':
                    ws[f'A{row}'].fill = self.estilos['aviso']
                
                row += 1
            
            row += 2
        
        # üÜï An√°lise de Sentimento
        if resumo.get('analise_sentimento'):
            ws[f'A{row}'] = "AN√ÅLISE DE SENTIMENTO DOS DOCUMENTOS"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            sentimento = resumo['analise_sentimento']
            ws[f'A{row}'] = "Tom Predominante"
            ws[f'B{row}'] = sentimento['predominante'].upper()
            ws[f'C{row}'] = sentimento['interpretacao']
            row += 1
            
            row += 1
        
        # üÜï Palavras-chave do Per√≠odo
        if resumo.get('palavras_chave_periodo'):
            ws[f'A{row}'] = "PALAVRAS-CHAVE DO PER√çODO (IA)"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            palavras = ", ".join(resumo['palavras_chave_periodo'])
            ws[f'A{row}'] = "Temas Principais"
            ws[f'B{row}'] = palavras
            row += 2
        
        # Fontes principais
        if resumo['fontes_principais']:
            ws[f'A{row}'] = "FONTES DE CONFIRMA√á√ÉO PRINCIPAIS"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            for fonte, qtd in resumo['fontes_principais'].items():
                ws[f'A{row}'] = fonte
                ws[f'B{row}'] = qtd
                row += 1
            
            row += 2
        
        # Recomenda√ß√µes
        if resumo['recomendacoes']:
            ws[f'A{row}'] = "RECOMENDA√á√ïES PRIORIT√ÅRIAS"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            for rec in resumo['recomendacoes']:
                ws[f'A{row}'] = f"‚ö†Ô∏è {rec['titulo']}"
                ws[f'B{row}'] = rec['descricao']
                ws[f'C{row}'] = rec.get('acao', '')
                
                # Cor baseada no tipo
                if rec['tipo'] == 'CR√çTICO':
                    ws[f'A{row}'].fill = self.estilos['alerta']
                elif rec['tipo'] == 'IMPORTANTE':
                    ws[f'A{row}'].fill = self.estilos['aviso']
                
                row += 1
        
        # Ajusta largura das colunas
        ws.column_dimensions['A'].width = 25
        ws.column_dimensions['B'].width = 20
        ws.column_dimensions['C'].width = 40


        return ws
    def _criar_analise_ia(self, documentos, normas):
        """üÜï Cria aba dedicada √†s an√°lises de IA"""
        ws = self.wb.create_sheet(title="ü§ñ An√°lise IA")
        
        row = 1
        
        # T√≠tulo
        ws.merge_cells(f'A{row}:E{row}')
        ws[f'A{row}'] = "AN√ÅLISES AVAN√áADAS COM INTELIG√äNCIA ARTIFICIAL"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['titulo_principal'])
        row += 2
        
        # Se√ß√£o 1: Resumos Inteligentes dos Documentos
        ws[f'A{row}'] = "RESUMOS INTELIGENTES DOS PRINCIPAIS DOCUMENTOS"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        # Cabe√ßalhos
        cabecalhos = ["Documento", "Resumo IA", "Palavras-chave", "Sentimento", "Relev√¢ncia"]
        for col, cabecalho in enumerate(cabecalhos, 1):
            ws.cell(row, col, cabecalho)
            self._aplicar_estilo(ws.cell(row, col), self.estilos['cabecalho'])
        row += 1
        
        # Processa amostra de documentos
        documentos_amostra = documentos[:10] if len(documentos) > 10 else documentos
        
        for doc in documentos_amostra:
            texto_para_analise = doc.resumo or doc.titulo or doc.assunto or ""
            
            if texto_para_analise:
                # Gera resumo IA
                resumo_ia = self.ia_gratuita.gerar_resumo_inteligente(texto_para_analise, 100)
                
                # Extrai palavras-chave
                palavras_chave = self.ia_gratuita.extrair_palavras_chave_ia(texto_para_analise, 5)
                
                # An√°lise de sentimento
                sentimento = self.ia_gratuita.analisar_sentimento_documento(texto_para_analise)
                
                # Preenche linha
                ws[f'A{row}'] = doc.titulo[:50] + "..." if len(doc.titulo) > 50 else doc.titulo
                ws[f'B{row}'] = resumo_ia
                ws[f'C{row}'] = ", ".join(palavras_chave[:3])
                ws[f'D{row}'] = f"{sentimento['sentimento']} ({sentimento['confianca']:.1%})"
                ws[f'E{row}'] = "ALTA" if doc.relevante_contabil else "BAIXA"
                
                # Colora√ß√£o baseada na relev√¢ncia
                if doc.relevante_contabil:
                    ws[f'E{row}'].fill = self.estilos['sucesso']
                
                # Quebra linha no resumo
                ws[f'B{row}'].alignment = Alignment(wrap_text=True, vertical='top')
                
                row += 1
        
        row += 2
        
        # Se√ß√£o 2: An√°lise de Tend√™ncias
        ws[f'A{row}'] = "TEND√äNCIAS IDENTIFICADAS PELA IA"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        # An√°lise de tend√™ncias
        analise_ia = AnaliseIA()
        tendencias = analise_ia.analisar_tendencias_normativas(documentos)
        
        # Normas mais citadas
        if tendencias['normas_mais_citadas']:
            ws[f'A{row}'] = "Top 5 Normas Mais Citadas"
            self._aplicar_estilo(ws[f'A{row}'], {'font': Font(bold=True)})
            row += 1
            
            for norma, freq in tendencias['normas_mais_citadas'][:5]:
                ws[f'A{row}'] = norma
                ws[f'B{row}'] = f"{freq} cita√ß√µes"
                row += 1
            
            row += 1
        
        # Assuntos emergentes
        if tendencias['assuntos_emergentes']:
            ws[f'A{row}'] = "Assuntos Emergentes Identificados"
            self._aplicar_estilo(ws[f'A{row}'], {'font': Font(bold=True)})
            row += 1
            
            for assunto, crescimento in tendencias['assuntos_emergentes'][:5]:
                ws[f'A{row}'] = assunto.title()
                ws[f'B{row}'] = f"Crescimento: +{crescimento}"
                ws[f'B{row}'].fill = self.estilos['sucesso'] if crescimento > 2 else self.estilos['aviso']
                row += 1
        
        # Se√ß√£o 3: Insights Autom√°ticos
        row += 2
        ws[f'A{row}'] = "INSIGHTS AUTOM√ÅTICOS GERADOS PELA IA"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        insights = self.ia_gratuita.gerar_insights_automaticos(documentos, normas)
        
        for insight in insights:
            ws[f'A{row}'] = f"üìã {insight['titulo']}"
            ws[f'B{row}'] = insight['descricao']
            ws[f'C{row}'] = insight.get('relevancia', 'm√©dia').upper()
            
            # Cor baseada na relev√¢ncia
            if insight.get('relevancia') == 'cr√≠tica':
                ws[f'C{row}'].fill = self.estilos['alerta']
            elif insight.get('relevancia') == 'alta':
                ws[f'C{row}'].fill = self.estilos['aviso']
            else:
                ws[f'C{row}'].fill = self.estilos['sucesso']
            
            ws[f'B{row}'].alignment = Alignment(wrap_text=True, vertical='top')
            row += 1
        
        # Nota sobre IA
        row += 2
        ws.merge_cells(f'A{row}:E{row}')
        ws[f'A{row}'] = "‚ÑπÔ∏è Nota: As an√°lises desta se√ß√£o foram geradas automaticamente por modelos de IA gratuitos. Os resultados devem ser validados por an√°lise humana."
        ws[f'A{row}'].alignment = Alignment(wrap_text=True)
        ws[f'A{row}'].fill = PatternFill(start_color="E3F2FD", end_color="E3F2FD", fill_type="solid")
        
        # Ajusta largura das colunas
        ws.column_dimensions['A'].width = 30
        ws.column_dimensions['B'].width = 50
        ws.column_dimensions['C'].width = 15
        ws.column_dimensions['D'].width = 20
        ws.column_dimensions['E'].width = 15
        
        # Define altura das linhas para melhor legibilidade
        for row_num in range(1, row + 1):
            ws.row_dimensions[row_num].height = 25
    
            return ws 

    def _criar_analise_documentos(self, documentos):
        """Cria aba com an√°lise detalhada dos documentos"""
        ws = self.wb.create_sheet(title="üìÑ Documentos")
        
        # Cabe√ßalhos
        cabecalhos = [
            "Data", "T√≠tulo", "Tipo", "Assunto", "Relevante", 
            "Processado", "Resumo IA", "Palavras-chave", "Fonte"
        ]
        
        for col, cabecalho in enumerate(cabecalhos, 1):
            ws.cell(1, col, cabecalho)
            self._aplicar_estilo(ws.cell(1, col), self.estilos['cabecalho'])
        
        # Dados
        for row, doc in enumerate(documentos, 2):
            # Gera resumo IA se n√£o existir
            resumo_ia = ""
            palavras_chave = ""
            
            if doc.titulo or doc.resumo:
                texto = doc.resumo or doc.titulo
                resumo_ia = self.ia_gratuita.gerar_resumo_inteligente(texto, 80)
                palavras_chave = ", ".join(self.ia_gratuita.extrair_palavras_chave_ia(texto, 3))
            
            ws[f'A{row}'] = doc.data_publicacao.strftime('%d/%m/%Y')
            ws[f'B{row}'] = doc.titulo
            ws[f'C{row}'] = doc.tipo_documento or 'N/A'
            ws[f'D{row}'] = doc.assunto or 'N/A'
            ws[f'E{row}'] = "SIM" if doc.relevante_contabil else "N√ÉO"
            ws[f'F{row}'] = "SIM" if doc.processado else "N√ÉO"
            ws[f'G{row}'] = resumo_ia
            ws[f'H{row}'] = palavras_chave
            ws[f'I{row}'] = doc.fonte_documento or 'N/A'
            
            # Colora√ß√£o
            if doc.relevante_contabil:
                ws[f'E{row}'].fill = self.estilos['sucesso']
            
            if not doc.processado:
                ws[f'F{row}'].fill = self.estilos['aviso']
            
            # Zebrado
            if row % 2 == 0:
                for col in range(1, len(cabecalhos) + 1):
                    ws.cell(row, col).fill = self.estilos['zebra']
        
        # Ajusta larguras
        larguras = [12, 40, 15, 30, 10, 12, 35, 25, 15]
        for col, largura in enumerate(larguras, 1):
            ws.column_dimensions[get_column_letter(col)].width = largura
    
    def _criar_analise_normas(self, normas):
        """Cria aba com an√°lise das normas"""
        ws = self.wb.create_sheet(title="üìã Normas")
        
        # Cabe√ßalhos
        cabecalhos = [
            "Tipo", "N√∫mero", "Ementa", "Situa√ß√£o", "√öltima Verifica√ß√£o", 
            "Fonte Confirma√ß√£o", "Data Vig√™ncia", "Observa√ß√µes"
        ]
        
        for col, cabecalho in enumerate(cabecalhos, 1):
            ws.cell(1, col, cabecalho)
            self._aplicar_estilo(ws.cell(1, col), self.estilos['cabecalho'])
        
        # Dados
        for row, norma in enumerate(normas, 2):
            ws[f'A{row}'] = norma.tipo
            ws[f'B{row}'] = norma.numero
            ws[f'C{row}'] = norma.ementa or 'N/A'
            ws[f'D{row}'] = norma.situacao
            ws[f'E{row}'] = norma.data_verificacao.strftime('%d/%m/%Y') if norma.data_verificacao else 'NUNCA'
            ws[f'F{row}'] = norma.fonte_confirmacao or 'N/A'
            ws[f'G{row}'] = norma.data_vigencia.strftime('%d/%m/%Y') if norma.data_vigencia else 'N/A'
            ws[f'H{row}'] = norma.observacoes or 'N/A'
            
            # Colora√ß√£o baseada na situa√ß√£o
            if norma.situacao == 'VIGENTE':
                ws[f'D{row}'].fill = self.estilos['sucesso']
            elif norma.situacao == 'REVOGADA':
                ws[f'D{row}'].fill = self.estilos['alerta']
            elif norma.situacao == 'N√ÉO ENCONTRADA':
                ws[f'D{row}'].fill = self.estilos['aviso']
            
            # Colora√ß√£o para verifica√ß√£o
            if not norma.data_verificacao:
                ws[f'E{row}'].fill = self.estilos['aviso']
            
            # Zebrado
            if row % 2 == 0:
                for col in range(1, len(cabecalhos) + 1):
                    ws.cell(row, col).fill = self.estilos['zebra']
        
        # Ajusta larguras
        larguras = [15, 15, 40, 15, 18, 20, 15, 30]
        for col, largura in enumerate(larguras, 1):
            ws.column_dimensions[get_column_letter(col)].width = largura
    
    def _criar_analise_compliance(self, normas):
        """Cria aba com an√°lise de compliance"""
        ws = self.wb.create_sheet(title="‚öñÔ∏è Compliance")
        
        row = 1
        
        # T√≠tulo
        ws.merge_cells(f'A{row}:D{row}')
        ws[f'A{row}'] = "AN√ÅLISE DE COMPLIANCE"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['titulo_principal'])
        row += 2
        
        # Estat√≠sticas gerais
        total_normas = len(normas)
        vigentes = len([n for n in normas if n.situacao == 'VIGENTE'])
        revogadas = len([n for n in normas if n.situacao == 'REVOGADA'])
        nao_encontradas = len([n for n in normas if n.situacao == 'N√ÉO ENCONTRADA'])
        nao_verificadas = len([n for n in normas if not n.data_verificacao])
        
        # Cria tabela de estat√≠sticas
        stats = [
            ("Total de Normas", total_normas),
            ("Normas Vigentes", vigentes),
            ("Normas Revogadas", revogadas),
            ("Normas N√£o Encontradas", nao_encontradas),
            ("Normas N√£o Verificadas", nao_verificadas),
            ("Taxa de Compliance", f"{(vigentes/total_normas*100):.1f}%" if total_normas > 0 else "0%")
        ]
        
        ws[f'A{row}'] = "ESTAT√çSTICAS GERAIS"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
        row += 1
        
        for desc, valor in stats:
            ws[f'A{row}'] = desc
            ws[f'B{row}'] = valor
            row += 1
        
        row += 2
        
        # Normas problem√°ticas
        normas_problematicas = [n for n in normas if n.situacao in ['REVOGADA', 'N√ÉO ENCONTRADA']]
        
        if normas_problematicas:
            ws[f'A{row}'] = "NORMAS PROBLEM√ÅTICAS (REQUER ATEN√á√ÉO)"
            self._aplicar_estilo(ws[f'A{row}'], self.estilos['cabecalho'])
            row += 1
            
            # Cabe√ßalhos
            cabecalhos = ["Tipo", "N√∫mero", "Situa√ß√£o", "√öltima Verifica√ß√£o"]
            for col, cabecalho in enumerate(cabecalhos, 1):
                ws.cell(row, col, cabecalho)
                self._aplicar_estilo(ws.cell(row, col), self.estilos['cabecalho'])
            row += 1
            
            for norma in normas_problematicas:
                ws[f'A{row}'] = norma.tipo
                ws[f'B{row}'] = norma.numero
                ws[f'C{row}'] = norma.situacao
                ws[f'D{row}'] = norma.data_verificacao.strftime('%d/%m/%Y') if norma.data_verificacao else 'NUNCA'
                
                # Cor de alerta
                for col in range(1, 5):
                    ws.cell(row, col).fill = self.estilos['alerta']
                
                row += 1
        
        # Ajusta larguras
        ws.column_dimensions['A'].width = 25
        ws.column_dimensions['B'].width = 20
        ws.column_dimensions['C'].width = 20
        ws.column_dimensions['D'].width = 20
    
    def _criar_tendencias_temporais(self, documentos):
        """Cria aba com an√°lise de tend√™ncias temporais"""
        ws = self.wb.create_sheet(title="üìà Tend√™ncias")
        
        # An√°lise por m√™s
        documentos_por_mes = defaultdict(int)
        relevantes_por_mes = defaultdict(int)
        
        for doc in documentos:
            mes_ano = doc.data_publicacao.strftime('%Y-%m')
            documentos_por_mes[mes_ano] += 1
            if doc.relevante_contabil:
                relevantes_por_mes[mes_ano] += 1
        
        # Cabe√ßalhos
        ws['A1'] = "M√™s/Ano"
        ws['B1'] = "Total Documentos"
        ws['C1'] = "Relevantes Cont√°bil"
        ws['D1'] = "Taxa Relev√¢ncia"
        
        for col in range(1, 5):
            self._aplicar_estilo(ws.cell(1, col), self.estilos['cabecalho'])
        
        # Dados
        meses_ordenados = sorted(documentos_por_mes.keys())
        for row, mes in enumerate(meses_ordenados, 2):
            total = documentos_por_mes[mes]
            relevantes = relevantes_por_mes[mes]
            taxa = (relevantes / total * 100) if total > 0 else 0
            
            ws[f'A{row}'] = mes
            ws[f'B{row}'] = total
            ws[f'C{row}'] = relevantes
            ws[f'D{row}'] = f"{taxa:.1f}%"
            
            # Colora√ß√£o baseada na taxa
            if taxa > 70:
                ws[f'D{row}'].fill = self.estilos['sucesso']
            elif taxa > 40:
                ws[f'D{row}'].fill = self.estilos['aviso']
            else:
                ws[f'D{row}'].fill = self.estilos['alerta']
        
        # Ajusta larguras
        ws.column_dimensions['A'].width = 12
        ws.column_dimensions['B'].width = 18
        ws.column_dimensions['C'].width = 18
        ws.column_dimensions['D'].width = 15
    
    def _criar_dashboard_visual(self, documentos, normas):
        """Cria aba com dashboard visual"""
        ws = self.wb.create_sheet(title="üìä Dashboard")
        
        # Esta fun√ß√£o pode ser expandida para incluir gr√°ficos
        # usando openpyxl.chart
        
        row = 1
        ws.merge_cells(f'A{row}:F{row}')
        ws[f'A{row}'] = "DASHBOARD VISUAL DE COMPLIANCE"
        self._aplicar_estilo(ws[f'A{row}'], self.estilos['titulo_principal'])
        row += 3
        
        # Resumo visual
        total_docs = len(documentos)
        docs_relevantes = len([d for d in documentos if d.relevante_contabil])
        total_normas = len(normas)
        normas_vigentes = len([n for n in normas if n.situacao == 'VIGENTE'])
        
        # Cards de estat√≠sticas
        cards = [
            ("üìÑ DOCUMENTOS", total_docs, "Total processados"),
            ("‚úÖ RELEVANTES", docs_relevantes, "Relev√¢ncia cont√°bil"),
            ("üìã NORMAS", total_normas, "Total catalogadas"),
            ("‚öñÔ∏è VIGENTES", normas_vigentes, "Status vigente")
        ]
        
        col_start = 1
        for i, (titulo, valor, desc) in enumerate(cards):
            col = col_start + (i * 2)
            
            # T√≠tulo do card
            ws.merge_cells(f'{get_column_letter(col)}{row}:{get_column_letter(col+1)}{row}')
            ws[f'{get_column_letter(col)}{row}'] = titulo
            self._aplicar_estilo(ws[f'{get_column_letter(col)}{row}'], self.estilos['cabecalho'])
            
            # Valor
            ws.merge_cells(f'{get_column_letter(col)}{row+1}:{get_column_letter(col+1)}{row+1}')
            ws[f'{get_column_letter(col)}{row+1}'] = valor
            ws[f'{get_column_letter(col)}{row+1}'].font = Font(size=20, bold=True)
            ws[f'{get_column_letter(col)}{row+1}'].alignment = Alignment(horizontal='center')
            
            # Descri√ß√£o
            ws.merge_cells(f'{get_column_letter(col)}{row+2}:{get_column_letter(col+1)}{row+2}')
            ws[f'{get_column_letter(col)}{row+2}'] = desc
            ws[f'{get_column_letter(col)}{row+2}'].alignment = Alignment(horizontal='center')
        
        # Ajusta larguras e alturas
        for col in range(1, 9):
            ws.column_dimensions[get_column_letter(col)].width = 15
        
        for r in range(row, row + 3):
            ws.row_dimensions[r].height = 30
    def _aplicar_estilo(self, cell, estilo):
        """Aplica estilo a uma c√©lula"""
        if isinstance(estilo, dict):
            if 'font' in estilo:
                cell.font = estilo['font']
            if 'fill' in estilo:
                cell.fill = estilo['fill']
            if 'alignment' in estilo:
                cell.alignment = estilo['alignment']
            if 'border' in estilo:
                cell.border = estilo['border']
        else:
            # Se estilo for PatternFill direto
            cell.fill = estilo


    def _formatar_resumo_ia_com_termos(self, documento_obj):
        if not documento_obj:
            return "Documento n√£o dispon√≠vel"

        resumo_base = documento_obj.resumo or ""
        texto_para_analise = documento_obj.texto_completo or resumo_base

        # Formata o resumo base (como voc√™ j√° faz)
        resumo_formatado = re.sub(r'\n+', ' ', resumo_base).strip()
        if len(resumo_formatado) > 250: # Limite para o resumo principal
            resumo_truncado = resumo_formatado[:250]
            ultimo_ponto = resumo_truncado.rfind('.')
            if ultimo_ponto > 150:
                resumo_formatado = resumo_truncado[:ultimo_ponto + 1]
            else:
                resumo_formatado = resumo_truncado + "..."
        
        if not resumo_formatado:
            resumo_formatado = "Resumo n√£o gerado ou indispon√≠vel."

        # Identifica termos monitorados encontrados
        termos_encontrados = []
        termos_monitorados_ativos = TermoMonitorado.objects.filter(ativo=True)
        for termo_obj in termos_monitorados_ativos:
            # Procura o termo principal e suas varia√ß√µes
            termos_para_buscar = [termo_obj.termo.lower()]
            if termo_obj.variacoes:
                termos_para_buscar.extend([v.strip().lower() for v in termo_obj.variacoes.split(',')])
            
            for t_busca in termos_para_buscar:
                if re.search(r'\b' + re.escape(t_busca) + r'\b', texto_para_analise.lower()):
                    if termo_obj.termo not in termos_encontrados: # Adiciona apenas o termo principal
                        termos_encontrados.append(termo_obj.termo)
                    break # Para de procurar varia√ß√µes se o termo principal ou uma varia√ß√£o foi encontrada

        output_final = resumo_formatado
        if termos_encontrados:
            output_final += f"\n\nTermos Relevantes Encontrados: {', '.join(termos_encontrados)}."
        
        return output_final

class AnaliseIA:
    """Classe para an√°lises com Intelig√™ncia Artificial"""
    
    def __init__(self):
        self.ia_gratuita = IAGratuita()
    
    def gerar_resumo_executivo(self, documentos, normas):
        """Gera resumo executivo com insights de IA"""
        try:
            # Estat√≠sticas b√°sicas
            total_documentos = len(documentos)
            documentos_contabeis = len([d for d in documentos if d.relevante_contabil])
            taxa_relevancia = (documentos_contabeis / total_documentos * 100) if total_documentos > 0 else 0
            
            total_normas = len(normas)
            normas_vigentes = len([n for n in normas if n.situacao == 'VIGENTE'])
            normas_revogadas = len([n for n in normas if n.situacao == 'REVOGADA'])
            normas_problematicas = len([n for n in normas if n.situacao in ['REVOGADA', 'N√ÉO ENCONTRADA']])
            
            # Determina per√≠odo de an√°lise
            if documentos:
                data_inicio = min(d.data_publicacao for d in documentos)
                data_fim = max(d.data_publicacao for d in documentos)
                periodo_analise = f"{data_inicio.strftime('%d/%m/%Y')} a {data_fim.strftime('%d/%m/%Y')}"
            else:
                periodo_analise = "Sem dados"
            
            # Calcula risco de compliance
            if normas_problematicas / total_normas > 0.3 if total_normas > 0 else True:
                risco_compliance = "ALTO"
            elif normas_problematicas / total_normas > 0.1 if total_normas > 0 else False:
                risco_compliance = "M√âDIO"
            else:
                risco_compliance = "BAIXO"
            
            # Gera insights com IA
            insights_ia = self._gerar_insights_executivos(documentos, normas)
            
            # An√°lise de sentimento dos documentos
            analise_sentimento = self._analisar_sentimento_geral(documentos)
            
            # Extrai palavras-chave do per√≠odo
            palavras_chave_periodo = self._extrair_palavras_chave_periodo(documentos)
            
            # Identifica fontes principais
            fontes_principais = self._identificar_fontes_principais(documentos)
            
            # Gera recomenda√ß√µes baseadas em IA
            recomendacoes = self._gerar_recomendacoes_ia(documentos, normas)
            
            return {
                'periodo_analise': periodo_analise,
                'total_documentos': total_documentos,
                'documentos_contabeis': documentos_contabeis,
                'taxa_relevancia_contabil': f"{taxa_relevancia:.1f}%",
                'total_normas': total_normas,
                'normas_vigentes': normas_vigentes,
                'normas_revogadas': normas_revogadas,
                'normas_problematicas': normas_problematicas,
                'risco_compliance': risco_compliance,
                'insights_ia': insights_ia,
                'analise_sentimento': analise_sentimento,
                'palavras_chave_periodo': palavras_chave_periodo,
                'fontes_principais': fontes_principais,
                'recomendacoes': recomendacoes
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar resumo executivo: {e}")
            return self._resumo_fallback(documentos, normas)
    
    def _gerar_insights_executivos(self, documentos, normas):
        """Gera insights executivos usando IA"""
        insights = []
        
        try:
            # Insight sobre evolu√ß√£o temporal
            if len(documentos) > 10:
                docs_recentes = [d for d in documentos if d.data_publicacao >= datetime.now().date() - timedelta(days=90)]
                if docs_recentes:
                    taxa_recente = len([d for d in docs_recentes if d.relevante_contabil]) / len(docs_recentes) * 100
                    
                    if taxa_recente > 70:
                        insights.append({
                            'titulo': 'Alta Atividade Regulat√≥ria Recente',
                            'descricao': f'Nos √∫ltimos 90 dias houve {len(docs_recentes)} publica√ß√µes com {taxa_recente:.1f}% de relev√¢ncia cont√°bil.',
                            'relevancia': 'alta'
                        })
            
            # Insight sobre compliance
            normas_nao_verificadas = len([n for n in normas if not n.data_verificacao])
            if normas_nao_verificadas > len(normas) * 0.2:  # Mais de 20% n√£o verificadas
                insights.append({
                    'titulo': 'Necessidade de Atualiza√ß√£o de Normas',
                    'descricao': f'{normas_nao_verificadas} normas n√£o foram verificadas recentemente.',
                    'relevancia': 'cr√≠tica'
                })
            
            # Insight sobre padr√µes identificados
            tipos_freq = defaultdict(int)
            for doc in documentos:
                if doc.tipo_documento:
                    tipos_freq[doc.tipo_documento] += 1
            
            if tipos_freq:
                tipo_mais_comum = max(tipos_freq.items(), key=lambda x: x[1])
                insights.append({
                    'titulo': f'Predomin√¢ncia de {tipo_mais_comum[0]}',
                    'descricao': f'O tipo de documento mais frequente √© {tipo_mais_comum[0]} com {tipo_mais_comum[1]} ocorr√™ncias.',
                    'relevancia': 'm√©dia'
                })
            
            return insights
            
        except Exception as e:
            logger.error(f"Erro ao gerar insights executivos: {e}")
            return []
    
    def _analisar_sentimento_geral(self, documentos):
        """Analisa o sentimento geral dos documentos"""
        try:
            if not documentos:
                return None
            
            # Pega uma amostra de documentos para an√°lise
            amostra = documentos[:20] if len(documentos) > 20 else documentos
            sentimentos = []
            
            for doc in amostra:
                texto = doc.resumo or doc.titulo or doc.assunto or ""
                if texto:
                    resultado = self.ia_gratuita.analisar_sentimento_documento(texto)
                    if resultado and 'sentimento' in resultado:
                        sentimentos.append(resultado['sentimento'])
            
            if sentimentos:
                # Conta os sentimentos
                contador = Counter(sentimentos)
                predominante = contador.most_common(1)[0][0]
                
                # Interpreta o resultado
                interpretacoes = {
                    'positivo': 'Documentos indicam cen√°rio favor√°vel e est√°vel',
                    'neutro': 'Documentos apresentam tom t√©cnico e informativo',
                    'negativo': 'Documentos indicam necessidade de aten√ß√£o e ajustes'
                }
                
                return {
                    'predominante': predominante,
                    'interpretacao': interpretacoes.get(predominante, 'Tom n√£o identificado'),
                    'distribuicao': dict(contador)
                }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de sentimento: {e}")
        
        return None
    
    def _extrair_palavras_chave_periodo(self, documentos):
        """Extrai palavras-chave do per√≠odo usando IA"""
        try:
            if not documentos:
                return []
            
            # Combina textos dos documentos mais recentes
            textos = []
            for doc in documentos[:30]:  # √öltimos 30 documentos
                texto = ""
                if doc.titulo:
                    texto += doc.titulo + " "
                if doc.resumo:
                    texto += doc.resumo + " "
                if doc.assunto:
                    texto += doc.assunto + " "
                
                if texto.strip():
                    textos.append(texto.strip())
            
            if textos:
                texto_combinado = " ".join(textos)
                palavras_chave = self.ia_gratuita.extrair_palavras_chave_ia(texto_combinado, 10)
                return palavras_chave[:8]  # Retorna top 8
            
        except Exception as e:
            logger.error(f"Erro ao extrair palavras-chave: {e}")
        
        return []
    
    def _identificar_fontes_principais(self, documentos):
        """Identifica as fontes principais dos documentos"""
        try:
            fontes = defaultdict(int)
            for doc in documentos:
                if doc.fonte:
                    fontes[doc.fonte_documento] += 1
            
            # Retorna as 5 principais
            return dict(sorted(fontes.items(), key=lambda x: x[1], reverse=True)[:5])
            
        except Exception as e:
            logger.error(f"Erro ao identificar fontes: {e}")
            return {}
    
    def _gerar_recomendacoes_ia(self, documentos, normas):
        """Gera recomenda√ß√µes baseadas em an√°lise IA"""
        recomendacoes = []
        
        try:
            # Recomenda√ß√£o sobre normas n√£o verificadas
            nao_verificadas = len([n for n in normas if not n.data_verificacao])
            if nao_verificadas > 0:
                tipo = 'CR√çTICO' if nao_verificadas > len(normas) * 0.3 else 'IMPORTANTE'
                recomendacoes.append({
                    'titulo': 'Verifica√ß√£o de Normas Pendentes',
                    'descricao': f'{nao_verificadas} normas precisam ser verificadas quanto ao status atual.',
                    'tipo': tipo,
                    'acao': 'Realizar verifica√ß√£o sistem√°tica das normas n√£o atualizadas'
                })
            
            # Recomenda√ß√£o sobre documentos n√£o processados
            nao_processados = len([d for d in documentos if not d.processado])
            if nao_processados > 0:
                recomendacoes.append({
                    'titulo': 'Processamento de Documentos Pendentes',
                    'descricao': f'{nao_processados} documentos est√£o aguardando processamento completo.',
                    'tipo': 'IMPORTANTE',
                    'acao': 'Finalizar an√°lise e categoriza√ß√£o dos documentos pendentes'
                })
            
            # Recomenda√ß√£o sobre baixa relev√¢ncia cont√°bil
            if documentos:
                taxa_relevancia = len([d for d in documentos if d.relevante_contabil]) / len(documentos)
                if taxa_relevancia < 0.3:  # Menos de 30% relevantes
                    recomendacoes.append({
                        'titulo': 'Revis√£o dos Crit√©rios de Relev√¢ncia',
                        'descricao': f'Apenas {taxa_relevancia:.1%} dos documentos foram classificados como relevantes contabilmente.',
                        'tipo': 'IMPORTANTE',
                        'acao': 'Revisar e ajustar crit√©rios de classifica√ß√£o de relev√¢ncia cont√°bil'
                    })
            
            # Recomenda√ß√£o sobre diversifica√ß√£o de fontes
            if len(self._identificar_fontes_principais(documentos)) < 3:
                recomendacoes.append({
                    'titulo': 'Diversifica√ß√£o de Fontes',
                    'descricao': 'Poucas fontes de informa√ß√£o identificadas no sistema.',
                    'tipo': 'SUGEST√ÉO',
                    'acao': 'Considerar amplia√ß√£o das fontes de monitoramento regulat√≥rio'
                })
            
            return recomendacoes
            
        except Exception as e:
            logger.error(f"Erro ao gerar recomenda√ß√µes: {e}")
            return []
    
    def analisar_tendencias_normativas(self, documentos):
        """Analisa tend√™ncias nas normas citadas"""
        try:
            # Extrai refer√™ncias a normas dos documentos
            normas_citadas = defaultdict(int)
            assuntos_freq = defaultdict(int)
            
            for doc in documentos:
                # Busca padr√µes de normas no texto
                texto_completo = f"{doc.titulo or ''} {doc.resumo or ''} {doc.assunto or ''}"
                
                # Padr√µes b√°sicos de normas (pode ser melhorado com regex mais sofisticado)
                import re
                padroes_normas = [
                    r'Lei\s+(?:n¬∫\s*)?(\d+(?:/\d+)?)',
                    r'Decreto\s+(?:n¬∫\s*)?(\d+(?:/\d+)?)',
                    r'Resolu√ß√£o\s+(?:n¬∫\s*)?(\d+(?:/\d+)?)',
                    r'Instru√ß√£o\s+Normativa\s+(?:n¬∫\s*)?(\d+(?:/\d+)?)',
                    r'CPC\s+(\d+)',
                    r'NBC\s+([A-Z]+\s*\d+)'
                ]
                
                for padrao in padroes_normas:
                    matches = re.findall(padrao, texto_completo, re.IGNORECASE)
                    for match in matches:
                        tipo_norma = padrao.split('\\')[0].replace('(?:n¬∫\\s*)?', '').strip()
                        norma_completa = f"{tipo_norma} {match}"
                        normas_citadas[norma_completa] += 1
                
                # Analisa assuntos
                if doc.assunto:
                    palavras_assunto = doc.assunto.lower().split()
                    for palavra in palavras_assunto:
                        if len(palavra) > 3:  # Ignora palavras muito pequenas
                            assuntos_freq[palavra] += 1
            
            # Identifica assuntos emergentes (simplificado)
            assuntos_emergentes = []
            if len(documentos) > 10:
                docs_recentes = documentos[:len(documentos)//2]  # Primeira metade (mais recentes)
                docs_antigos = documentos[len(documentos)//2:]   # Segunda metade (mais antigos)
                
                assuntos_recentes = defaultdict(int)
                assuntos_antigos = defaultdict(int)
                
                for doc in docs_recentes:
                    if doc.assunto:
                        for palavra in doc.assunto.lower().split():
                            if len(palavra) > 3:
                                assuntos_recentes[palavra] += 1
                
                for doc in docs_antigos:
                    if doc.assunto:
                        for palavra in doc.assunto.lower().split():
                            if len(palavra) > 3:
                                assuntos_antigos[palavra] += 1
                
                # Calcula crescimento
                for assunto, freq_recente in assuntos_recentes.items():
                    freq_antiga = assuntos_antigos.get(assunto, 0)
                    if freq_antiga > 0:
                        crescimento = ((freq_recente - freq_antiga) / freq_antiga) * 100
                        if crescimento > 50:  # Crescimento significativo
                            assuntos_emergentes.append((assunto, int(crescimento)))
                    elif freq_recente > 2:  # Novo assunto com frequ√™ncia relevante
                        assuntos_emergentes.append((assunto, 100))  # 100% novo
            
            return {
                'normas_mais_citadas': sorted(normas_citadas.items(), key=lambda x: x[1], reverse=True),
                'assuntos_emergentes': sorted(assuntos_emergentes, key=lambda x: x[1], reverse=True),
                'assuntos_frequentes': sorted(assuntos_freq.items(), key=lambda x: x[1], reverse=True)
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de tend√™ncias: {e}")
            return {
                'normas_mais_citadas': [],
                'assuntos_emergentes': [],
                'assuntos_frequentes': []
            }
    
    def _resumo_fallback(self, documentos, normas):
        """Retorna resumo b√°sico em caso de erro na IA"""
        total_documentos = len(documentos)
        documentos_contabeis = len([d for d in documentos if d.relevante_contabil])
        total_normas = len(normas)
        normas_vigentes = len([n for n in normas if n.situacao == 'VIGENTE'])
        
        return {
            'periodo_analise': 'N√£o dispon√≠vel',
            'total_documentos': total_documentos,
            'documentos_contabeis': documentos_contabeis,
            'taxa_relevancia_contabil': f"{(documentos_contabeis/total_documentos*100):.1f}%" if total_documentos > 0 else "0%",
            'total_normas': total_normas,
            'normas_vigentes': normas_vigentes,
            'normas_revogadas': 0,
            'normas_problematicas': 0,
            'risco_compliance': 'N√ÉO CALCULADO',
            'insights_ia': [],
            'analise_sentimento': None,
            'palavras_chave_periodo': [],
            'fontes_principais': {},
            'recomendacoes': []
        }


class IAGratuita:
    """Classe para integra√ß√£o com servi√ßos de IA gratuitos"""
    
    def __init__(self):
        # Aqui voc√™ pode configurar APIs gratuitas como Hugging Face, etc.
        pass
    
    def gerar_resumo_inteligente(self, texto, max_palavras=100):
        """Gera resumo inteligente do texto (vers√£o simplificada)"""
        try:
            if not texto or len(texto.strip()) == 0:
                return "Texto n√£o dispon√≠vel para resumo"
            
            # Implementa√ß√£o simplificada - em produ√ß√£o, use uma API de IA
            frases = texto.split('.')
            frases = [f.strip() for f in frases if f.strip()]
            
            if len(frases) <= 2:
                return texto[:max_palavras*7]  # Aproximadamente 7 chars por palavra
            
            # Pega as primeiras e √∫ltimas frases mais relevantes
            resumo_frases = []
            if frases:
                resumo_frases.append(frases[0])  # Primeira frase
                if len(frases) > 2:
                    resumo_frases.append(frases[len(frases)//2])  # Frase do meio
                if len(frases) > 1:
                    resumo_frases.append(frases[-1])  # √öltima frase
            
            resumo = '. '.join(resumo_frases)
            
            # Trunca se necess√°rio
            palavras = resumo.split()
            if len(palavras) > max_palavras:
                resumo = ' '.join(palavras[:max_palavras]) + '...'
            
            return resumo
            
        except Exception as e:
            logger.error(f"Erro ao gerar resumo: {e}")
            return "Erro na gera√ß√£o do resumo"
    
    def extrair_palavras_chave_ia(self, texto, quantidade=5):
        """Extrai palavras-chave do texto (vers√£o simplificada)"""
        try:
            if not texto:
                return []
            
            # Implementa√ß√£o simplificada - em produ√ß√£o, use TF-IDF ou NLP
            import re
            from collections import Counter
            
            # Remove pontua√ß√£o e converte para min√∫sculas
            texto_limpo = re.sub(r'[^\w\s]', ' ', texto.lower())
            palavras = texto_limpo.split()
            
            # Remove palavras muito comuns (stop words b√°sicas)
            stop_words = {
                'a', 'o', 'e', 'de', 'do', 'da', 'dos', 'das', 'em', 'no', 'na', 'nos', 'nas',
                'por', 'para', 'com', 'sem', 'sob', 'sobre', 'entre', 'que', 'se', '√©', 's√£o',
                'foi', 'ser√°', 'ter', 'tem', 'sua', 'seu', 'seus', 'suas', 'este', 'esta',
                'isto', 'esse', 'essa', 'isso', 'aquele', 'aquela', 'aquilo', 'um', 'uma',
                'uns', 'umas', 'como', 'quando', 'onde', 'porque', 'assim', 'mais', 'menos',
                'muito', 'pouco', 'bem', 'mal', 'j√°', 'ainda', 'tamb√©m', 's√≥', 'apenas'
            }
            
            # Filtra palavras relevantes
            palavras_relevantes = [
                palavra for palavra in palavras 
                if len(palavra) > 3 and palavra not in stop_words
            ]
            
            # Conta frequ√™ncia
            contador = Counter(palavras_relevantes)
            
            # Retorna as mais frequentes
            return [palavra for palavra, freq in contador.most_common(quantidade)]
            
        except Exception as e:
            logger.error(f"Erro ao extrair palavras-chave: {e}")
            return []
    
    def analisar_sentimento_documento(self, texto):
        """Analisa sentimento do documento (vers√£o simplificada)"""
        try:
            if not texto:
                return {'sentimento': 'neutro', 'confianca': 0.5}
            
            # Implementa√ß√£o simplificada baseada em palavras-chave
            palavras_positivas = {
                'aprovado', 'aprova√ß√£o', 'benef√≠cio', 'melhoria', 'otimiza√ß√£o', 'efici√™ncia',
                'crescimento', 'desenvolvimento', 'sucesso', 'adequado', 'conforme', 'regular',
                'est√°vel', 'favor√°vel', 'positivo', 'satisfat√≥rio', 'cumprido'
            }
            
            palavras_negativas = {
                'problema', 'erro', 'falha', 'inadequado', 'irregular', 'pendente', 'atraso',
                'risco', 'aten√ß√£o', 'cuidado', 'revis√£o', 'corre√ß√£o', 'ajuste', 'n√£o conforme',
                'viola√ß√£o', 'infra√ß√£o', 'multa', 'penalidade', 'descumprimento', 'cr√≠tico'
            }
            
            texto_lower = texto.lower()
            
            score_positivo = sum(1 for palavra in palavras_positivas if palavra in texto_lower)
            score_negativo = sum(1 for palavra in palavras_negativas if palavra in texto_lower)
            
            if score_positivo > score_negativo:
                sentimento = 'positivo'
                confianca = min(0.8, 0.5 + (score_positivo - score_negativo) * 0.1)
            elif score_negativo > score_positivo:
                sentimento = 'negativo'
                confianca = min(0.8, 0.5 + (score_negativo - score_positivo) * 0.1)
            else:
                sentimento = 'neutro'
                confianca = 0.6
            
            return {
                'sentimento': sentimento,
                'confianca': confianca,
                'score_positivo': score_positivo,
                'score_negativo': score_negativo
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de sentimento: {e}")
            return {'sentimento': 'neutro', 'confianca': 0.5}
    
    def gerar_insights_automaticos(self, documentos, normas):
        """Gera insights autom√°ticos baseados nos dados"""
        insights = []
        
        try:
            # Insight sobre volume de documentos
            if len(documentos) > 100:
                insights.append({
                    'titulo': 'Alto Volume de Documentos',
                    'descricao': f'Sistema processou {len(documentos)} documentos, indicando alta atividade regulat√≥ria.',
                    'relevancia': 'alta'
                })
            
            # Insight sobre compliance
            normas_vigentes = len([n for n in normas if n.situacao == 'VIGENTE'])
            if normas_vigentes / len(normas) > 0.8 if normas else False:
                insights.append({
                    'titulo': 'Boa Taxa de Compliance',
                    'descricao': f'{(normas_vigentes/len(normas)*100):.1f}% das normas est√£o vigentes.',
                    'relevancia': 'm√©dia'
                })
            
            # Insight sobre processamento
            nao_processados = len([d for d in documentos if not d.processado])
            if nao_processados > len(documentos) * 0.1:  # Mais de 10%
                insights.append({
                    'titulo': 'Documentos Aguardando Processamento',
                    'descricao': f'{nao_processados} documentos ainda n√£o foram totalmente processados.',
                    'relevancia': 'cr√≠tica'
                })
            
            return insights
            
        except Exception as e:
            logger.error(f"Erro ao gerar insights autom√°ticos: {e}")
            return []